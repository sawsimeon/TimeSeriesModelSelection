{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection Enhancements\n",
    "\n",
    "This notebook implements enhancements to the time series model selection framework (Python-only). It includes:\n",
    "- RMSE_holdout (last-block holdout) selection method\n",
    "- Grid search ETS fitting with an L2 penalty on parameters\n",
    "- Rolling-origin cross-validation (expanding window) for model selection\n",
    "- Weighted selection criterion C = w * RMSE_train + (1-w) * complexity\n",
    "- Comparisons across selection methods and plotting/saving outputs\n",
    "\n",
    "Notes and assumptions:\n",
    "- Uses Python libraries: numpy, pandas, matplotlib, sklearn, statsmodels\n",
    "- Attempts to load M1/M3/M4 datasets from the repository `data/` folder if present. If not found, the code demonstrates methods on a toy dataset and includes code to download datasets if needed (commented).\n",
    "- For yearly series, the default holdout horizon = 6 (years). For other frequencies, horizon is inferred or 20% of training set is used.\n",
    "- ETS fitting uses statsmodels' ExponentialSmoothing when possible; a custom grid-search wrapper is provided to emulate R-style parameter selection and an L2 penalty on smoothing parameters.\n",
    "\n",
    "All outputs (CSV tables and PNG plots) are saved under `notebooks/outputs/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and setup\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# Create outputs dir\n",
    "OUTPUT_DIR = 'notebooks/outputs'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions\n",
    "- RMSE\n",
    "- split_last_block (for RMSE_holdout)\n",
    "- ETS grid search with L2 penalty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def split_last_block(ts, holdout_pct=None, holdout_horizon=None, freq=None):\n",
    "    \"\"\"Split a time series (pd.Series) into train and holdout (last block).\n",
    "    Provide either holdout_pct (fraction) or holdout_horizon (integer points).\n",
    "    Returns: train_series, holdout_series\n",
    "    \"\"\"\n",
    "    n = len(ts)\n",
    "    if holdout_horizon is not None:\n",
    "        h = int(holdout_horizon)\n",
    "    elif holdout_pct is not None:\n",
    "        h = max(1, int(np.ceil(n * holdout_pct)))\n",
    "    else:\n",
    "        # default 20%\n",
    "        h = max(1, int(np.ceil(n * 0.2)))\n",
    "    if h >= n:\n",
    "        raise ValueError('Holdout horizon >= series length')\n",
    "    train = ts.iloc[:-h]\n",
    "    holdout = ts.iloc[-h:]\n",
    "    return train, holdout\n",
    "\n",
    "def ets_grid_search(ts_train, ts_holdout, seasonal_periods=None, param_grid=None, l2_penalty=0.01, seasonal=None, trend_options=[None,'add','mul'], damped_options=[False, True], maxiter=100):\n",
    "    \"\"\"Grid search over ETS model configurations and smoothing params.\n",
    "    Uses statsmodels ExponentialSmoothing with optimized=False for explicit smoothing params.\n",
    "    param_grid: dict with keys 'alpha','beta','gamma' ranges (iterables)\n",
    "    Returns best_model_info dict and DataFrame of results.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    # Default param ranges if not provided\n",
    "    if param_grid is None:\n",
    "        param_grid = {\n",
    "            'alpha': np.linspace(0.01, 0.99, 10),\n",
    "            'beta': np.linspace(0.0, 0.5, 6),\n",
    "            'gamma': np.linspace(0.0, 0.5, 6)\n",
    "        }\n",
    "    # For yearly data, seasonal is typically None; seasonal_periods None means no seasonality\n",
    "    for trend in trend_options:\n",
    "        for damped in damped_options:\n",
    "            # If seasonality not desired skip gamma loops\n",
    "            seasonal_range = param_grid.get('gamma', [0.0]) if seasonal is not None else [0.0]\n",
    "            for alpha in param_grid['alpha']:\n",
    "                for beta in param_grid['beta']:\n",
    "                    for gamma in seasonal_range:\n",
    "                        try:\n",
    "                            model = ExponentialSmoothing(ts_train, trend=trend, damped_trend=damped, seasonal=seasonal, seasonal_periods=seasonal_periods)\n",
    "                            # Fit with provided smoothing params (do not optimize inside fit)\n",
    "                            fit_kwargs = dict(smoothing_level=alpha)\n",
    "                            if trend is not None:\n",
    "                                fit_kwargs['smoothing_slope'] = beta\n",
    "                                # statsmodels expects damping_slope only when optimized; for fixed smoothing params we may leave it\n",
    "                            if seasonal is not None:\n",
    "                                fit_kwargs['smoothing_seasonal'] = gamma\n",
    "                            fitted = model.fit(optimized=False, use_brute=False, start_params=None, **fit_kwargs)\n",
    "                            # Forecast for holdout horizon\n",
    "                            h = len(ts_holdout)\n",
    "                            fc = fitted.forecast(h)\n",
    "                            score = rmse(ts_holdout.values, fc)\n",
    "                            # L2 penalty on parameters\n",
    "                            l2 = l2_penalty * (alpha**2 + beta**2 + gamma**2)\n",
    "                            penalized_score = score + l2\n",
    "                            results.append({\n",
    "                                'trend': trend,\n",
    "                                'damped': damped,\n",
    "                                'alpha': float(alpha),\n",
    "                                'beta': float(beta),\n",
    "                                'gamma': float(gamma),\n",
    "                                'rmse_holdout': float(score),\n",
    "                                'penalized_rmse': float(penalized_score)\n",
    "                            })\n",
    "                        except Exception as e:\n",
    "                            # skip configurations that fail\n",
    "                            # print('skip', trend, damped, alpha, beta, gamma, e)\n",
    "                            continue\n",
    "    df = pd.DataFrame(results)\n",
    "    if df.empty:\n",
    "        raise RuntimeError('No successful ETS fits during grid search')\n",
    "    best_row = df.loc[df['rmse_holdout'].idxmin()]\n",
    "    return best_row.to_dict(), df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy dataset demo\n",
    "Generate a toy daily series (100 points, 2023-01-01 to 2023-04-10) and run the selection methods to demonstrate outputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toy dataset (100 daily samples)\n",
    "rng = pd.date_range('2023-01-01', periods=100, freq='D')\n",
    "np.random.seed(0)\n",
    "toy_values = 10 + np.linspace(0, 2, 100) + np.sin(np.linspace(0, 6.28, 100)) + np.random.normal(0, 0.5, 100)\n",
    "toy_series = pd.Series(toy_values, index=rng).rename('toy')\n",
    "\n",
    "# Split last block: use 20% holdout\n",
    "train, holdout = split_last_block(toy_series, holdout_pct=0.2)\n",
    "print('toy length', len(toy_series), 'train', len(train), 'holdout', len(holdout))\n",
    "\n",
    "# Simple ETS grid for toy dataset (seasonality daily -> weekly?)\n",
    "seasonal = 'add'  # toy has weekly-ish pattern but keep simple\n",
    "seasonal_periods = 7\n",
    "param_grid = {\n",
    "    'alpha': np.linspace(0.01, 0.9, 8),\n",
    "    'beta': np.linspace(0.0, 0.5, 5),\n",
    "    'gamma': np.linspace(0.0, 0.5, 5)\n",
    "}\n",
    "best_info, grid_df = ets_grid_search(train, holdout, seasonal_periods=seasonal_periods, param_grid=param_grid, l2_penalty=0.01, seasonal=seasonal, trend_options=[None,'add'], damped_options=[False])\n",
    "best_info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling-origin cross-validation (expanding window)\n",
    "Implements expanding training windows and fixed test horizon. Returns average RMSE across folds for a given ETS configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_origin_cv(ts, initial_train_size, horizon, step=1, trend=None, seasonal=None, seasonal_periods=None, alpha=None, beta=None, gamma=None, l2_penalty=0.0):\n",
    "    \"\"\"Perform rolling-origin CV with expanding window.\n",
    "    ts: pd.Series\n",
    "    initial_train_size: number of points to start with\n",
    "    horizon: fixed forecast horizon\n",
    "    step: step size for advancing origin\n",
    "    Returns mean RMSE across folds and list of fold RMSEs\n",
    "    \"\"\"\n",
    "    n = len(ts)\n",
    "    fold_rmse = []\n",
    "    start = initial_train_size\n",
    "    while start + horizon <= n:\n",
    "        train = ts.iloc[:start]\n",
    "        test = ts.iloc[start:start+horizon]\n",
    "        try:\n",
    "            model = ExponentialSmoothing(train, trend=trend, seasonal=seasonal, seasonal_periods=seasonal_periods)\n",
    "            fit_kwargs = {}\n",
    "            if alpha is not None:\n",
    "                fit_kwargs['smoothing_level'] = alpha\n",
    "            if beta is not None and trend is not None:\n",
    "                fit_kwargs['smoothing_slope'] = beta\n",
    "            if gamma is not None and seasonal is not None:\n",
    "                fit_kwargs['smoothing_seasonal'] = gamma\n",
    "            fitted = model.fit(optimized=False, **fit_kwargs)\n",
    "            fc = fitted.forecast(horizon)\n",
    "            s = rmse(test.values, fc)\n",
    "            penalized = s + l2_penalty * sum([(p or 0.0)**2 for p in [alpha, beta, gamma]])\n",
    "            fold_rmse.append(penalized)\n",
    "        except Exception:\n",
    "            # if fit fails, append a large penalty\n",
    "            fold_rmse.append(np.nan)\n",
    "        start += step\n",
    "    fold_rmse = [x for x in fold_rmse if not np.isnan(x)]\n",
    "    if not fold_rmse:\n",
    "        return np.nan, []\n",
    "    return float(np.mean(fold_rmse)), fold_rmse\n",
    "\n",
    "# Example of rolling CV on toy series\n",
    "mean_rmse, folds = rolling_origin_cv(toy_series, initial_train_size=50, horizon=5, step=5, trend='add', seasonal='add', seasonal_periods=7, alpha=0.3, beta=0.05, gamma=0.05)\n",
    "mean_rmse, folds[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted criterion C = w * RMSE_train + (1-w) * complexity\n",
    "Complexity is number of ETS parameters used: alpha (1), beta (if trend) (+1), gamma (if seasonal) (+1). We'll test weights w in {0.3,0.5,0.7}.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complexity_of_config(trend=None, seasonal=None):\n",
    "    c = 1  # alpha always present\n",
    "    if trend is not None:\n",
    "        c += 1\n",
    "    if seasonal is not None:\n",
    "        c += 1\n",
    "    return c\n",
    "\n",
    "def select_by_weighted_criterion(ts_train, ts_holdout, configs, w=0.5, l2_penalty=0.0):\n",
    "    \"\"\"configs: iterable of dicts with keys trend, seasonal, alpha,beta,gamma,seasonal_periods,damped\n",
    "    Returns best config by criterion C.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for cfg in configs:\n",
    "        try:\n",
    "            model = ExponentialSmoothing(ts_train, trend=cfg.get('trend'), damped_trend=cfg.get('damped', False), seasonal=cfg.get('seasonal'), seasonal_periods=cfg.get('seasonal_periods'))\n",
    "            fit_kwargs = {}\n",
    "            if 'alpha' in cfg:\n",
    "                fit_kwargs['smoothing_level'] = cfg['alpha']\n",
    "            if 'beta' in cfg and cfg.get('trend') is not None:\n",
    "                fit_kwargs['smoothing_slope'] = cfg['beta']\n",
    "            if 'gamma' in cfg and cfg.get('seasonal') is not None:\n",
    "                fit_kwargs['smoothing_seasonal'] = cfg['gamma']\n",
    "            fitted = model.fit(optimized=False, **fit_kwargs)\n",
    "            h = len(ts_holdout)\n",
    "            fc = fitted.forecast(h)\n",
    "            rmse_hold = rmse(ts_holdout.values, fc)\n",
    "            rmse_train = rmse(ts_train.values, fitted.fittedvalues)\n",
    "            complexity = complexity_of_config(cfg.get('trend'), cfg.get('seasonal'))\n",
    "            C = w * rmse_train + (1-w) * complexity\n",
    "            rows.append({**cfg, 'rmse_holdout':rmse_hold, 'rmse_train':rmse_train, 'complexity':complexity, 'C':C})\n",
    "        except Exception:\n",
    "            continue\n",
    "    df = pd.DataFrame(rows)\n",
    "    if df.empty:\n",
    "        return None, df\n",
    "    best = df.loc[df['C'].idxmin()].to_dict()\n",
    "    return best, df\n",
    "\n",
    "# Example configs (small) for toy data\n",
    "configs = [\n",
    "    {'trend':None, 'seasonal':'add', 'seasonal_periods':7, 'alpha':0.2, 'beta':0.0, 'gamma':0.1, 'damped':False},\n",
    "    {'trend':'add', 'seasonal':'add', 'seasonal_periods':7, 'alpha':0.3, 'beta':0.05, 'gamma':0.05, 'damped':False},\n",
    "    {'trend':'add', 'seasonal':None, 'alpha':0.4, 'beta':0.1, 'gamma':0.0, 'damped':False}\n",
    "]\n",
    "best_w, dfw = select_by_weighted_criterion(train, holdout, configs, w=0.5)\n",
    "best_w\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save demonstration outputs (toy) — RMSE comparison table & plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For demonstration create a small comparison table for toy series using several selection criteria\n",
    "comparison = []\n",
    "\n",
    "# 1) AICc / AIC - approximate via fitted model.aic (statsmodels provides aic)\n",
    "try:\n",
    "    m_full = ExponentialSmoothing(train, trend='add', seasonal='add', seasonal_periods=7).fit(optimized=True)\n",
    "    aic_full = m_full.aic if hasattr(m_full, 'aic') else np.nan\n",
    "except Exception:\n",
    "    aic_full = np.nan\n",
    "\n",
    "# 2) RMSE_train (choose model with lowest in-sample RMSE) - we evaluate three candidate configs\n",
    "candidate_configs = configs\n",
    "best_by_train = None\n",
    "min_train_rmse = np.inf\n",
    "for cfg in candidate_configs:\n",
    "    try:\n",
    "        model = ExponentialSmoothing(train, trend=cfg.get('trend'), seasonal=cfg.get('seasonal'), seasonal_periods=cfg.get('seasonal_periods'))\n",
    "        fit_kwargs = {}\n",
    "        if 'alpha' in cfg:\n",
    "            fit_kwargs['smoothing_level'] = cfg['alpha']\n",
    "        if 'beta' in cfg and cfg.get('trend') is not None:\n",
    "            fit_kwargs['smoothing_slope'] = cfg['beta']\n",
    "        fitted = model.fit(optimized=False, **fit_kwargs)\n",
    "        train_rmse = rmse(train.values, fitted.fittedvalues)\n",
    "        test_rmse = rmse(holdout.values, fitted.forecast(len(holdout)))\n",
    "        if train_rmse < min_train_rmse:\n",
    "            min_train_rmse = train_rmse\n",
    "            best_by_train = {'cfg':cfg, 'train_rmse':train_rmse, 'test_rmse':test_rmse}\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "# 3) RMSE_holdout from previous grid search (best_info)\n",
    "best_holdout = best_info\n",
    "\n",
    "# 4) Weighted criterion best (w=0.5)\n",
    "best_weighted = best_w\n",
    "\n",
    "comparison = pd.DataFrame([\n",
    "    {'method':'AICc/AIC', 'rmse_test': (aic_full if np.isfinite(aic_full) else np.nan)},\n",
    "    {'method':'RMSE_train', 'rmse_test': best_by_train['test_rmse'] if best_by_train is not None else np.nan},\n",
    "    {'method':'RMSE_holdout', 'rmse_test': best_holdout.get('rmse_holdout', np.nan)},\n",
    "    {'method':'Weighted_w0.5', 'rmse_test': best_weighted.get('rmse_holdout') if best_weighted is not None else np.nan}\n",
    "])\n",
    "comparison.to_csv(os.path.join(OUTPUT_DIR, 'rmse_comparison_table.csv'), index=False)\n",
    "\n",
    "ax = comparison.set_index('method').plot(kind='bar', legend=False, ylabel='RMSE / AIC(approx)')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, 'rmse_comparison_plot.png'), dpi=200)\n",
    "comparison\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps and placeholders for working on M1/M3/M4 datasets\n",
    "The repository may include M1, M3, M4 files under `data/`. If available, the next cells should:\n",
    "- Load yearly series subsets from M1/M3/M4\n",
    "- For each series, run model selection methods (AICC/BIC/RMSE_train/RMSE_holdout/rolling CV/weighted)\n",
    "- Aggregate results into CSVs and plots as specified in the task.\n",
    "\n",
    "Because dataset file formats vary (e.g., nested lists in .txt, .csv of series), the notebook provides utility code below to try to detect and load series files. If files are not present, the notebook will continue with toy demo only and documents that dataset loading is required.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_series_files(data_dir='data'):\n",
    "    \"\"\"Look for likely M1/M3/M4 files in repository data folder.\"\"\"\n",
    "    if not os.path.exists(data_dir):\n",
    "        return []\n",
    "    files = []\n",
    "    for root, dirs, filenames in os.walk(data_dir):\n",
    "        for fn in filenames:\n",
    "            if fn.lower().endswith(('.csv', '.txt', '.tsv', '.dat')):\n",
    "                files.append(os.path.join(root, fn))\n",
    "    return files\n",
    "\n",
    "files = find_series_files('data')\n",
    "files[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation cell — CV definition and Fotios Fig 2 reproduction notes\n",
    "This notebook assumes CV in Fotios' paper refers to rolling-origin cross-validation with expanding windows and a fixed horizon (e.g., 6 years for yearly series). The notebook provides a rolling-origin implementation and a plan to reproduce Fig 2 by comparing AIC-based selection vs CV-based selection across a subset of series, plotting median RMSE_test or similar metrics. If data or exact R supplementary code differences exist, the notebook documents them and provides a reproducible Python alternative.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next actions (to be implemented by script `scripts/model_selection_v3.py`)\n",
    "- Wrap the selection methods into reusable functions in scripts/model_selection_v3.py\n",
    "- Batch process the toy and M1/M3/M4 series, create CSV result tables, and save plots.\n",
    "\n",
    "This notebook demonstrates the algorithms and saves example outputs for the toy dataset. Proceed to create the script that will run the full experiments and produce all deliverables when datasets are available.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
