{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import itertools as itt\n",
    "import numbers\n",
    "from typing import Iterable, Tuple "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define purge function to remove overlapping training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def purge(cv, train_indices, test_fold_start, test_fold_end):\n",
    "    \"\"\"\n",
    "    Remove training indices where prediction times overlap with test fold's evaluation times.\n",
    "    This prevents leakage by ensuring no training sample's pred_time falls within the test fold's time range.\n",
    "    \"\"\"\n",
    "    train_times = cv.pred_times.iloc[train_indices]\n",
    "    eval_times_test = cv.eval_times.iloc[test_fold_start:test_fold_end]\n",
    "    pred_times_test = cv.pred_times.iloc[test_fold_start:test_fold_end]\n",
    "    \n",
    "    # Mask to exclude train indices where pred_time is within [min(pred_times_test), max(eval_times_test)]\n",
    "    mask = ~((train_times >= pred_times_test.min()) & \n",
    "             (train_times <= eval_times_test.max()))\n",
    "    return train_indices[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define embargo function to enforce a time gap between train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embargo(cv, train_indices, test_indices, test_fold_end):\n",
    "    \"\"\"\n",
    "    Apply embargo by removing training samples where pred_time is too close to test eval_time.\n",
    "    This ensures a temporal buffer (embargo period) to prevent leakage due to temporal correlation.\n",
    "    \"\"\"\n",
    "    eval_times_test = cv.eval_times.iloc[test_indices]\n",
    "    max_eval_time = eval_times_test.max()\n",
    "    embargo_time = max_eval_time + cv.embargo_td\n",
    "    \n",
    "    train_times = cv.pred_times.iloc[train_indices]\n",
    "    mask = train_times < embargo_time\n",
    "    return train_indices[mask]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define base class for time series cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseTimeSeriesCrossValidator:\n",
    "    \"\"\"\n",
    "    Abstract base class for time series cross-validation.\n",
    "    Ensures samples have prediction and evaluation times, and enforces time-ordering and index alignment.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_splits=10):\n",
    "        # Validate n_splits as an integer >= 2\n",
    "        if not isinstance(n_splits, numbers.Integral):\n",
    "            raise ValueError(f\"The number of folds must be of Integral type. {n_splits} of type {type(n_splits)} was passed.\")\n",
    "        n_splits = int(n_splits)\n",
    "        if n_splits <= 1:\n",
    "            raise ValueError(f\"K-fold cross-validation requires at least one train/test split by setting n_splits = 2 or more, got n_splits = {n_splits}.\")\n",
    "        self.n_splits = n_splits\n",
    "        self.pred_times = None\n",
    "        self.eval_times = None\n",
    "        self.indices = None\n",
    "\n",
    "    def split(self, X: pd.DataFrame, y: pd.Series = None, pred_times: pd.Series = None, eval_times: pd.Series = None):\n",
    "        \"\"\"\n",
    "        Validate input data and store prediction/evaluation times and indices.\n",
    "        Ensures X, y, pred_times, and eval_times are pandas objects with aligned indices and sorted times.\n",
    "        \"\"\"\n",
    "        if not isinstance(X, pd.DataFrame) and not isinstance(X, pd.Series):\n",
    "            raise ValueError('X should be a pandas DataFrame/Series.')\n",
    "        if not isinstance(y, pd.Series) and y is not None:\n",
    "            raise ValueError('y should be a pandas Series.')\n",
    "        if not isinstance(pred_times, pd.Series):\n",
    "            raise ValueError('pred_times should be a pandas Series.')\n",
    "        if not isinstance(eval_times, pd.Series):\n",
    "            raise ValueError('eval_times should be a pandas Series.')\n",
    "        if y is not None and (X.index == y.index).sum() != len(y):\n",
    "            raise ValueError('X and y must have the same index')\n",
    "        if (X.index == pred_times.index).sum() != len(pred_times):\n",
    "            raise ValueError('X and pred_times must have the same index')\n",
    "        if (X.index == eval_times.index).sum() != len(eval_times):\n",
    "            raise ValueError('X and eval_times must have the same index')\n",
    "\n",
    "        if not pred_times.equals(pred_times.sort_values()):\n",
    "            raise ValueError('pred_times should be sorted')\n",
    "        if not eval_times.equals(eval_times.sort_values()):\n",
    "            raise ValueError('eval_times should be sorted')\n",
    "\n",
    "        self.pred_times = pred_times\n",
    "        self.eval_times = eval_times\n",
    "        self.indices = np.arange(X.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define class purged combinatorial K-fold cross-validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombPurgedKFoldCVLocal(BaseTimeSeriesCrossValidator):\n",
    "    \"\"\"\n",
    "    Implements purged and embargoed combinatorial K-fold cross-validation.\n",
    "    Splits data into n_splits folds, uses n_test_splits folds as test set, and purges/embargoes to prevent leakage.\n",
    "    Based on Marcos Lopez de Prado's 'Advances in Financial Machine Learning'.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_splits=10, n_test_splits=2, embargo_td=pd.Timedelta(minutes=0)):\n",
    "        # Initialize base class and validate n_test_splits and embargo_td\n",
    "        super().__init__(n_splits)\n",
    "        if not isinstance(n_test_splits, numbers.Integral):\n",
    "            raise ValueError(f\"The number of test folds must be of Integral type. {n_test_splits} of type {type(n_test_splits)} was passed.\")\n",
    "        n_test_splits = int(n_test_splits)\n",
    "        if n_test_splits <= 0 or n_test_splits > self.n_splits - 1:\n",
    "            raise ValueError(f\"K-fold cross-validation requires at least one train/test split by setting n_test_splits between 1 and n_splits - 1, got n_test_splits = {n_test_splits}.\")\n",
    "        self.n_test_splits = n_test_splits\n",
    "        if not isinstance(embargo_td, pd.Timedelta):\n",
    "            raise ValueError(f\"The embargo time should be of type Pandas Timedelta. {embargo_td} of type {type(embargo_td)} was passed.\")\n",
    "        if embargo_td < pd.Timedelta(minutes=0):\n",
    "            raise ValueError(f\"The embargo time should be positive, got embargo = {embargo_td}.\")\n",
    "        self.embargo_td = embargo_td\n",
    "\n",
    "    def split(self, X: pd.DataFrame, y: pd.Series = None, pred_times: pd.Series = None, eval_times: pd.Series = None) -> Iterable[Tuple[np.ndarray, np.ndarray]]:\n",
    "        \"\"\"\n",
    "        Generate train/test indices for each fold.\n",
    "        Yields purged and embargoed train/test indices to prevent temporal leakage.\n",
    "        \"\"\"\n",
    "        super().split(X, y, pred_times, eval_times)\n",
    "        # Create fold boundaries\n",
    "        fold_bounds = [(fold[0], fold[-1] + 1) for fold in np.array_split(self.indices, self.n_splits)]\n",
    "        # Generate all combinations of n_test_splits folds for test sets\n",
    "        selected_fold_bounds = list(itt.combinations(fold_bounds, self.n_test_splits))\n",
    "        selected_fold_bounds.reverse()  # Start with test set at the end\n",
    "\n",
    "        for fold_bound_list in selected_fold_bounds:\n",
    "            test_fold_bounds, test_indices = self.compute_test_set(fold_bound_list)\n",
    "            train_indices = self.compute_train_set(test_fold_bounds, test_indices)\n",
    "            yield train_indices, test_indices\n",
    "\n",
    "    def compute_train_set(self, test_fold_bounds: list, test_indices: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Compute training indices by excluding test indices and applying purge/embargo.\n",
    "        \"\"\"\n",
    "        train_indices = np.setdiff1d(self.indices, test_indices)\n",
    "        for test_fold_start, test_fold_end in test_fold_bounds:\n",
    "            train_indices = purge(self, train_indices, test_fold_start, test_fold_end)\n",
    "            train_indices = embargo(self, train_indices, test_indices, test_fold_end)\n",
    "        return train_indices\n",
    "\n",
    "    def compute_test_set(self, fold_bound_list: list) -> Tuple[list, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Compute test indices and fold boundaries for the test set.\n",
    "        Merges contiguous folds and collects all test indices.\n",
    "        \"\"\"\n",
    "        test_indices = np.empty(0)\n",
    "        test_fold_bounds = []\n",
    "        for fold_start, fold_end in fold_bound_list:\n",
    "            if not test_fold_bounds or fold_start != test_fold_bounds[-1][-1]:\n",
    "                test_fold_bounds.append((fold_start, fold_end))\n",
    "            elif fold_start == test_fold_bounds[-1][-1]:\n",
    "                test_fold_bounds[-1] = (test_fold_bounds[-1][0], fold_end)\n",
    "            test_indices = np.union1d(test_indices, self.indices[fold_start:fold_end]).astype(int)\n",
    "        return test_fold_bounds, test_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate synthetic time series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)  # For reproducibility\n",
    "n_samples = 100\n",
    "dates = pd.date_range(start='2023-01-01', periods=n_samples, freq='D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create feature DataFrame with two random features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame({\n",
    "    'feature1': np.random.randn(n_samples),\n",
    "    'feature2': np.random.randn(n_samples)\n",
    "}, index=dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create target series as a linear combination of features plus noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.Series(np.random.randn(n_samples) + 0.5 * X['feature1'] + 0.3 * X['feature2'], index=dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define prediction and evaluation times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_times = pd.Series(dates, index=dates)  # Prediction at index time\n",
    "eval_times = pd.Series(dates + pd.Timedelta(days=1), index=dates)  # Evaluation 1 day later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize cross-validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 5 folds, 1 test fold per round, and 2-day embargo\n",
    "cv = CombPurgedKFoldCVLocal(n_splits=5, n_test_splits=1, embargo_td=pd.Timedelta(days=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform cross-validation with Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "  Train indices: [0 1 2 3 4]... (length: 80)\n",
      "  Test indices: [80 81 82 83 84]... (length: 20)\n",
      "  MSE: 0.8725\n",
      "\n",
      "Fold 2:\n",
      "  Train indices: [0 1 2 3 4]... (length: 61)\n",
      "  Test indices: [60 61 62 63 64]... (length: 20)\n",
      "  MSE: 1.6806\n",
      "\n",
      "Fold 3:\n",
      "  Train indices: [0 1 2 3 4]... (length: 41)\n",
      "  Test indices: [40 41 42 43 44]... (length: 20)\n",
      "  MSE: 1.3040\n",
      "\n",
      "Fold 4:\n",
      "  Train indices: [0 1 2 3 4]... (length: 21)\n",
      "  Test indices: [20 21 22 23 24]... (length: 20)\n",
      "  MSE: 1.2827\n",
      "\n",
      "Fold 5:\n",
      "  Train indices: [21]... (length: 1)\n",
      "  Test indices: [0 1 2 3 4]... (length: 20)\n",
      "  MSE: 8.4302\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "mse_scores = []\n",
    "fold = 1\n",
    "\n",
    "for train_indices, test_indices in cv.split(X, y, pred_times, eval_times):\n",
    "    # Split data into train and test sets\n",
    "    X_train, X_test = X.iloc[train_indices], X.iloc[test_indices]\n",
    "    y_train, y_test = y.iloc[train_indices], y.iloc[test_indices]\n",
    "    \n",
    "    # Train model and predict\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_scores.append(mse)\n",
    "    \n",
    "    # Print fold details\n",
    "    print(f\"Fold {fold}:\")\n",
    "    print(f\"  Train indices: {train_indices[:5]}... (length: {len(train_indices)})\")\n",
    "    print(f\"  Test indices: {test_indices[:5]}... (length: {len(test_indices)})\")\n",
    "    print(f\"  MSE: {mse:.4f}\\n\")\n",
    "    fold += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize cross-validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Results:\n",
      "Mean MSE: 2.7140\n",
      "Std MSE: 2.8695\n"
     ]
    }
   ],
   "source": [
    "print(\"Cross-Validation Results:\")\n",
    "print(f\"Mean MSE: {np.mean(mse_scores):.4f}\")\n",
    "print(f\"Std MSE: {np.std(mse_scores):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
