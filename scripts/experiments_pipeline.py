#!/usr/bin/env python3
\"\"\"\nexperiments_pipeline.py\n\nParsers and batch experiment pipeline for M4/M3/M1-style datasets.\n\nUsage (once datasets are available under data/raw):\n  python3 scripts/experiments_pipeline.py --dataset data/raw/M4_yearly_train.csv --testset data/raw/M4_yearly_test.csv --freq yearly --subset 100\n\nThis script does NOT download datasets. Place raw CSVs in data/raw before running.\n\nOutputs:\n  - notebooks/outputs/rmse_comparison_table_full.csv\n  - notebooks/outputs/fotios_fig2_reproduction.png\n  - notebooks/outputs/rmse_holdout_vs_rolling_origin_full.csv\n  - notebooks/outputs/weighted_criterion_comparison_full.csv\n\nNotes:\n- Parsers assume each row is: SERIES_ID, val1, val2, ..., valN (M4-style). Non-numeric entries are ignored.\n- For M1/M3 formats, you may need to pre-convert into this CSV layout or extend the parser.\n\"\"\"\n\nimport os\nimport argparse\nimport csv\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom statsmodels.tsa.holtwinters import ExponentialSmoothing\nfrom sklearn.metrics import mean_squared_error\nimport warnings\n\nwarnings.simplefilter('ignore')\n\nOUTPUT_DIR = 'notebooks/outputs'\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\n\ndef rmse(y_true, y_pred):\n    return np.sqrt(mean_squared_error(y_true, y_pred))\n\n\ndef parse_series_csv(path, max_series=None):\n    \"\"\"Parse M4-style CSV where each row is: id, v1, v2, ..., vN\n    Returns list of tuples (series_id, pd.Series(values)).\n    \"\"\"\n    series = []\n    with open(path, 'r', newline='') as f:\n        reader = csv.reader(f)\n        for i, row in enumerate(reader):\n            if not row:\n                continue\n            sid = row[0]\n            vals = []\n            for v in row[1:]:\n                try:\n                    if v is None or v == '':\n                        continue\n                    vals.append(float(v))\n                except Exception:\n                    # try to strip non-numeric chars\n                    vv = ''.join(ch for ch in v if (ch.isdigit() or ch in '.-eE'))\n                    try:\n                        if vv:\n                            vals.append(float(vv))\n                    except Exception:\n                        continue\n            if len(vals) == 0:\n                continue\n            s = pd.Series(vals)\n            series.append((sid, s))\n            if max_series is not None and len(series) >= max_series:\n                break\n    return series\n\n\ndef split_last_block(ts, holdout_pct=None, holdout_horizon=None):\n    n = len(ts)\n    if holdout_horizon is not None:\n        h = int(holdout_horizon)\n    elif holdout_pct is not None:\n        h = max(1, int(np.ceil(n * holdout_pct)))\n    else:\n        h = max(1, int(np.ceil(n * 0.2)))\n    if h >= n:\n        raise ValueError('Holdout horizon >= series length')\n    train = ts.iloc[:-h]\n    holdout = ts.iloc[-h:]\n    return train, holdout\n\n\ndef ets_fit_and_forecast(train, h, trend=None, seasonal=None, seasonal_periods=None,\n                         alpha=None, beta=None, gamma=None, damped=False):\n    fit_kwargs = {}\n    if alpha is not None:\n        fit_kwargs['smoothing_level'] = float(alpha)\n    if beta is not None and trend is not None:\n        fit_kwargs['smoothing_slope'] = float(beta)\n    if gamma is not None and seasonal is not None:\n        fit_kwargs['smoothing_seasonal'] = float(gamma)\n    model = ExponentialSmoothing(train, trend=trend, seasonal=seasonal, seasonal_periods=seasonal_periods, damped_trend=damped)\n    fitted = model.fit(optimized=False, **fit_kwargs)\n    fc = fitted.forecast(h)\n    return fitted, fc\n\n\ndef ets_grid_search_basic(train, holdout, seasonal_periods=None, param_grid=None, l2_penalty=0.01,\n                          seasonal=None, trend_options=[None, 'add'], damped_options=[False], max_configs=200):\n    # Lightweight grid search with a cap on configs to avoid long runs\n    results = []\n    if param_grid is None:\n        param_grid = {\n            'alpha': np.linspace(0.05, 0.6, 5),\n            'beta': np.linspace(0.0, 0.3, 3),\n            'gamma': np.linspace(0.0, 0.3, 3)\n        }\n    seasonal_range = param_grid.get('gamma', [0.0]) if seasonal is not None else [0.0]\n    count = 0\n    for trend in trend_options:\n        for damped in damped_options:\n            for alpha in param_grid['alpha']:\n                for beta in param_grid['beta']:\n                    for gamma in seasonal_range:\n                        if count >= max_configs:\n                            break\n                        try:\n                            fitted, fc = ets_fit_and_forecast(train, len(holdout), trend=trend, seasonal=seasonal,\n                                                              seasonal_periods=seasonal_periods, alpha=alpha, beta=beta, gamma=gamma, damped=damped)\n                            score = rmse(holdout.values, fc)\n                            l2 = l2_penalty * (float(alpha)**2 + float(beta)**2 + float(gamma)**2)\n                            results.append({'trend': trend, 'damped': damped, 'alpha': float(alpha), 'beta': float(beta), 'gamma': float(gamma), 'rmse_holdout': float(score), 'penalized': float(score + l2)})\n                            count += 1\n                        except Exception:\n                            continue\n                    if count >= max_configs:\n                        break\n                if count >= max_configs:\n                    break\n            if count >= max_configs:\n                break\n        if count >= max_configs:\n            break\n    df = pd.DataFrame(results)\n    if df.empty:\n        return None, df\n    best = df.loc[df['rmse_holdout'].idxmin()].to_dict()\n    return best, df\n\n\ndef rolling_origin_cv_score(ts, initial_train_size, horizon, step=1, trend=None, seasonal=None, seasonal_periods=None,\n                            alpha=None, beta=None, gamma=None, l2_penalty=0.0):\n    n = len(ts)\n    fold_scores = []\n    start = initial_train_size\n    while start + horizon <= n:\n        train = ts.iloc[:start]\n        test = ts.iloc[start:start+horizon]\n        try:\n            _, fc = ets_fit_and_forecast(train, horizon, trend=trend, seasonal=seasonal, seasonal_periods=seasonal_periods,\n                                         alpha=alpha, beta=beta, gamma=gamma)\n            s = rmse(test.values, fc)\n            penalized = s + l2_penalty * sum([(p or 0.0)**2 for p in [alpha, beta, gamma]])\n            fold_scores.append(penalized)\n        except Exception:\n            fold_scores.append(np.nan)\n        start += step\n    fold_scores = [x for x in fold_scores if not np.isnan(x)]\n    if not fold_scores:\n        return np.nan, []\n    return float(np.mean(fold_scores)), fold_scores\n\n\ndef complexity_of_config(trend=None, seasonal=None):\n    c = 1\n    if trend is not None:\n        c += 1\n    if seasonal is not None:\n        c += 1\n    return c\n\n\ndef select_by_weighted_criterion_grid(train, holdout, configs, w=0.5):\n    rows = []\n    for cfg in configs:\n        try:\n            fitted, fc = ets_fit_and_forecast(train, len(holdout), trend=cfg.get('trend'), seasonal=cfg.get('seasonal'), seasonal_periods=cfg.get('seasonal_periods'),\n                                             alpha=cfg.get('alpha'), beta=cfg.get('beta'), gamma=cfg.get('gamma'), damped=cfg.get('damped', False))\n            rmse_hold = rmse(holdout.values, fc)\n            rmse_train = rmse(train.values, fitted.fittedvalues)\n            complexity = complexity_of_config(cfg.get('trend'), cfg.get('seasonal'))\n            C = w * rmse_train + (1.0 - w) * complexity\n            rows.append({**cfg, 'rmse_holdout': rmse_hold, 'rmse_train': rmse_train, 'complexity': complexity, 'C': C})\n        except Exception:\n            continue\n    df = pd.DataFrame(rows)\n    if df.empty:\n        return None, df\n    best = df.loc[df['C'].idxmin()].to_dict()\n    return best, df\n\n\ndef run_series_experiment(series_id, series, horizon=6, freq='Y'):\n    # Determine holdout horizon for yearly series default 6\n    if freq in ('Y', 'yearly'):\n        h = horizon\n    else:\n        # default to 20% if not yearly\n        h = max(1, int(np.ceil(len(series) * 0.2)))\n\n    # Split last block for RMSE_holdout\n    try:\n        train, holdout = split_last_block(series, holdout_horizon=h)\n    except Exception:\n        return None\n\n    # Define small candidate configs (for speed)\n    configs = [\n        {'trend': None, 'seasonal': None, 'seasonal_periods': None, 'alpha': 0.2, 'beta': 0.0, 'gamma': 0.0, 'damped': False},\n        {'trend': 'add', 'seasonal': None, 'seasonal_periods': None, 'alpha': 0.3, 'beta': 0.05, 'gamma': 0.0, 'damped': False},\n        {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 1, 'alpha': 0.3, 'beta': 0.05, 'gamma': 0.05, 'damped': False}\n    ]\n\n    # RMSE_train selection (pick best by in-sample fit among configs)\n    best_by_train = None\n    min_train_rmse = np.inf\n    for cfg in configs:\n        try:\n            fitted, fc = ets_fit_and_forecast(train, len(holdout), trend=cfg.get('trend'), seasonal=cfg.get('seasonal'), seasonal_periods=cfg.get('seasonal_periods'),\n                                             alpha=cfg.get('alpha'), beta=cfg.get('beta'), gamma=cfg.get('gamma'), damped=cfg.get('damped', False))\n            tr_rmse = rmse(train.values, fitted.fittedvalues)\n            if tr_rmse < min_train_rmse:\n                min_train_rmse = tr_rmse\n                best_by_train = {'cfg': cfg, 'rmse_train': tr_rmse, 'rmse_test': rmse(holdout.values, fc)}\n        except Exception:\n            continue\n\n    # RMSE_holdout via grid search\n    best_holdout, df_grid = ets_grid_search_basic(train, holdout, seasonal_periods=None, param_grid=None, l2_penalty=0.01, seasonal=None, trend_options=[None,'add'], damped_options=[False], max_configs=60)\n\n    # Rolling-origin CV selection: for simplicity evaluate configs by rolling CV and pick best\n    best_by_cv = None\n    min_cv = np.inf\n    initial_train = max(3, int(len(series) * 0.5))  # start with half series\n    horizon_cv = h\n    for cfg in configs:\n        try:\n            mean_cv, folds = rolling_origin_cv_score(series, initial_train, horizon_cv, step=horizon_cv, trend=cfg.get('trend'), seasonal=cfg.get('seasonal'), seasonal_periods=cfg.get('seasonal_periods'), alpha=cfg.get('alpha'), beta=cfg.get('beta'), gamma=cfg.get('gamma'))\n            if np.isfinite(mean_cv) and mean_cv < min_cv:\n                min_cv = mean_cv\n                best_by_cv = {'cfg': cfg, 'cv_score': mean_cv}\n        except Exception:\n            continue\n\n    # Weighted criterion: try w in [0.3,0.5,0.7] on configs\n    weighted_results = []\n    for w in [0.3, 0.5, 0.7]:\n        best_w, dfw = select_by_weighted_criterion_grid(train, holdout, configs, w=w)\n        if best_w is not None:\n            best_w['w'] = w\n            weighted_results.append(best_w)\n\n    # Evaluate selected models on holdout/test\n    out = {\n        'series_id': series_id,\n        'len': len(series),\n        'rmse_train_selected': best_by_train['rmse_test'] if best_by_train else np.nan,\n        'rmse_holdout_grid': best_holdout.get('rmse_holdout') if best_holdout else np.nan,\n        'rolling_cv_score': best_by_cv['cv_score'] if best_by_cv else np.nan,\n        'weighted_best': weighted_results\n    }\n    return out\n\n\ndef batch_run(dataset_path, testset_path=None, freq='yearly', subset=None, out_prefix='full'):\n    series_list = parse_series_csv(dataset_path, max_series=subset)\n    results = []\n    for sid, s in series_list:\n        try:\n            res = run_series_experiment(sid, s, horizon=6 if freq in ('yearly','Y') else None, freq=freq)\n            if res is not None:\n                results.append(res)\n        except Exception:\n            continue\n\n    # Convert results into DataFrame summaries\n    rows = []\n    for r in results:\n        rows.append({'series_id': r['series_id'], 'len': r['len'], 'rmse_holdout_grid': r['rmse_holdout_grid'], 'rolling_cv_score': r['rolling_cv_score']})\n    df = pd.DataFrame(rows)\n    csv_out = os.path.join(OUTPUT_DIR, f'rmse_comparison_table_{out_prefix}.csv')\n    df.to_csv(csv_out, index=False)\n\n    # Simple plots\n    if not df.empty:\n        df_plot = df[['rmse_holdout_grid','rolling_cv_score']].dropna()\n        if not df_plot.empty:\n            plt.figure()\n            df_plot.boxplot()\n            plt.ylabel('RMSE')\n            plt.title('RMSE comparison across series')\n            plt.tight_layout()\n            plt.savefig(os.path.join(OUTPUT_DIR, f'rmse_comparison_plot_{out_prefix}.png'), dpi=200)\n            plt.close()\n\n    # Save other outputs paths as placeholders (Fotios fig reproducible code would go here)\n    print('Saved summary CSV to', csv_out)\n    return df\n\n\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--dataset', required=True, help='Path to training CSV (M4-style)')\n    parser.add_argument('--testset', required=False, help='Path to test CSV if available')\n    parser.add_argument('--freq', default='yearly', choices=['yearly','monthly','daily','Y','M','D'], help='Series frequency')\n    parser.add_argument('--subset', type=int, default=None, help='Limit number of series to process (for quick runs)')\n    parser.add_argument('--out', default='full', help='Output prefix')\n    args = parser.parse_args()\n\n    print('Parsing dataset:', args.dataset)\n    df_summary = batch_run(args.dataset, testset_path=args.testset, freq=args.freq, subset=args.subset, out_prefix=args.out)\n    print('Done. Summary rows:', len(df_summary))\n
